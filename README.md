# ğŸ½ï¸ Food Demand & Waste Forecasting System

A complete end-to-end system for forecasting **food demand** and **food waste** using deep learning, real-time data, and optimized workflows.

---

## Key Features

âœ… Dual-objective (demand & waste) forecast  
âœ… Integrates real-time weather from [Open-Meteo API](https://open-meteo.com/)  
âœ… Optimized LSTM (Optuna-tuned hyperparameters)  
âœ… Production Flask REST API  
âœ… Logs predictions to `predictions.db` (SQLite)  
âœ… Automated testing with `pytest`  
âœ… End-to-end scripts and modular codebase

---

## Project Structure

food-demand-and-waste-forecasting/
â”‚
â”œâ”€â”€ api_integrations/ # Fetches external data (e.g., weather)
â”œâ”€â”€ config/ # Stores configuration variables
â”œâ”€â”€ data/ # For data generation and validation
â”œâ”€â”€ database/ # Manages database connections and operations
â”œâ”€â”€ deployment/ # Contains the Flask API and deployment scripts
â”œâ”€â”€ models/ # Defines model architectures
â”œâ”€â”€ monitoring/ # (Future) For model performance monitoring
â”œâ”€â”€ prediction/ # Handles the prediction logic
â”œâ”€â”€ preprocessing/ # Data cleaning and feature engineering pipeline
â”œâ”€â”€ scheduler/ # (Future) For automated, recurring tasks
â”œâ”€â”€ saved_models/ # Stores trained model artifacts
â”œâ”€â”€ tests/ # Automated tests for the application
â”œâ”€â”€ training/ # Scripts for model training and hyperparameter tuning
â””â”€â”€ utils/ # Utility functions (e.g., visualization)

## âš™ï¸ How to Run This Project

**1. Install dependencies**
pip install -r requirements.txt

**2. Generate sample data**
python scripts/generate_dataset.py

Generates food demand/waste data + weather.

**3. Train the model**
python scripts/train_model.py

Artifacts: `lstm_model.keras`, `scaler_X.pkl`, `scaler_y.pkl`

**4. Start the API**
python app/api.py

**5. Make a prediction**

Example: send last 10 weeks (each row = [demand, waste, temp, humidity, ...]):
curl -X POST http://127.0.0.1:5001/predict
-H "Content-Type: application/json"
-d '{
"past_weeks_data": [
[400, 32, 24.5, 72], [420, 34, 23.9, 70], ... (10 arrays total)
]
}'

**Expected JSON Reply:**
{
"forecast": {
"next_week_demand": 425,
"next_week_waste": 35.2
},
"status": "success"
}

All predictions are saved to `predictions.db`.

---

## ğŸ§© Example Weather API Response

Weather data is fetched for enrichment (example from Open-Meteo):
{
"latitude": 28.6,
"longitude": 77.2,
"daily": {
"temperature_2m_max": [35.2, 34.9, ...],
"temperature_2m_min": [27.6, 27.5, ...],
"precipitation_sum": [0.15, 0.00, ...]
}
}

Your data prep automatically parses and integrates this.

---

## ğŸ§  Model Architecture

**Multi-output LSTM:**

- Input: 10 weeks of demand, waste, weather features
- Hidden Layer: LSTM (tuned units, dropout)
- Output:
  - Next week demand
  - Next week waste

Input (10 timesteps, N features)
â”‚
[LSTM Layer(s)]
â”‚
[Dense Layers]
/
Demand Waste

**Auto-tuning:** Run
python scripts/hyperparameter_tuning.py

to find best LSTM units, learning rate, etc.

---

## ğŸ§ª Automated Testing

Test endpoints, data integrations, and modeling logic:
pytest tests/

---

## ğŸ¯ Model Evaluation

Visualize predictions vs actual:
python scripts/evaluate_model.py

---

## ğŸ³ Dockerization (optional)

Add a Dockerfile for easy cloud or container deploy.

---

## ğŸ¤– Extending This Project

- Swap in advanced models (see: `models/`)
- Build retraining with `scheduler/scheduler.py`
- Integrate more external signals (e.g., holidays, local events)
- Add visualization dashboards

---

## ğŸ¤ Contact

Questions/collaboration:  
iampayal018@gmail.com
